{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heatmap-gen\n",
    "This notebook collects all the steps to generate a heatmap from a Strava archive or just a collection of gpx files.\n",
    "\n",
    "Generating a heatmap from a Strava archive consists of the following steps:\n",
    "- Convert non-gpx files to gpx, collect metadata of gpx files\n",
    "- Merge all the gpx files of certain activity types together into one large gpx\n",
    "- (Optional) Generate the background map for the heatmap, alternatively: use one of the pregenerated ones\n",
    "- Generate the heatlayer(s) from the merged gpx files and put them on the background map\n",
    "\n",
    "### How to use\n",
    "Each step has its own section. The section starts with some explanation about what the section does and how to use it.\n",
    "\n",
    "After the textblock, there is usually a codeblock with parameter definitions (in all caps).\n",
    "You can change the behaviour of the code by changing the values of these parameters.\n",
    "This should be the only part of the code where you need to make changes!\n",
    "The following blocks of code execute all necessary operations for that step.\n",
    "\n",
    "Each step can be run separately. For example if you have already generated maps or use pregenerated ones, you can skip the step \"generate maps\". If you just want to regenerate a heatmap with different colors, running only the last step is enough."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries\n",
    "Some libraries are required to process the data and generate maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add tools folder to path\n",
    "import sys\n",
    "sys.path.insert(1, \"../tools\")\n",
    "\n",
    "# work with the metadata csv's\n",
    "import pandas as pd\n",
    "# fast array manipulations\n",
    "import numpy as np\n",
    "# use system commands\n",
    "import os\n",
    "\n",
    "# main tool to manipulate gpx files\n",
    "import gpxpy\n",
    "from gpxpy import gpxxml as gpxml\n",
    "import geopy.distance\n",
    "\n",
    "# the workhorse for map generation, provides routines to download tiles and do some\n",
    "# coordinate transforms\n",
    "import cartopy.io.img_tiles as cartotiles\n",
    "# polygons to define regions\n",
    "from shapely.geometry.polygon import Polygon\n",
    "# more coordinate support\n",
    "import globalmaptiles as gmaptiles\n",
    "# for parallel downloads\n",
    "import concurrent.futures\n",
    "\n",
    "# image manipulating and saving\n",
    "from PIL import Image\n",
    "# for the colormaps\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Strava metadata\n",
    "In this step metadata about the activities such the activitytype is extracted from the strava archive.\n",
    "\n",
    "If you do not want to select activities based on type, you can skip to the next part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder containing the strava archive\n",
    "STRAVA_FOLDER = \"../stravadata/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_headers = [\n",
    "    \"Activity-ID\", \"Date\", \"Name\", \"Activitytype\", \"Description\", \"Elapsed time\",\n",
    "    \"Distance\", \"Max. heartrate\", \"Similar attempts\", \"Home-work\", \"Private note\", \"Gear\",\n",
    "    \"Filename\", \"Weight athlete\", \"Weight bike\", \"Elapsed time.1\", \"Moving time\", \"Distance.1\",\n",
    "    \"Max. speed\", \"Average speed\", \"Elevation gain\", \"Elevation loss\", \"Lowest elevation\", \"Highest elevations\",\n",
    "    \"Max. grade\", \"Average grade\", \"Average positive grade\", \"Average negative grade\", \"Max. cadans\",\n",
    "    \"Average cadans\", \"Max. heartrate.1\", \"Average heartrate\", \"Max. power\", \"Average power\", \"Calories\",\n",
    "    \"Max. temperature\", \"Average temperature\", \"Similar attempt.1\", \"Total work\", \"Number runningsessions\",\n",
    "    \"Time downhill\", \"Time uphill\", \"Other time\", \"Pervieved effort\", \"Type\", \"Start Time\",\n",
    "    \"Weighted average power\", \"Amount powerdata\", \"Preference percieved effort\", \"Percieved similar attempt\",\n",
    "    \"Home-work.1\", \"Total weight\", \"Uploaded from\", \"Grade adjusted distance\", \"Time weather\",\n",
    "    \"Weather\", \"Outside temperature\", \"Percieved temperature\", \"Dewpoint\", \"Humidity\", \"Pressure\",\n",
    "    \"Windspeed\", \"Windgust\", \"Wind direction\", \"Precipation intensity\", \"Sunrise\", \"Sunset\",\n",
    "    \"Moonphase\", \"Bike\", \"Gear 2\", \"Precipation probability\", \"Precipation type\", \"Cloud cover\",\n",
    "    \"Visibility\", \"UV-index\", \"Ozonvalue\", \"Jump count\", \"Total grit\", \"Average flow\",\n",
    "    \"Flagged\", \"Avg elapsed speed\", \"Dirt distance\", \"Newly explored distance\", \"Newly explored dirt distance\",\n",
    "    \"Sport type\", \"Total steps\", \"Media\"\n",
    "]\n",
    "\n",
    "df = pd.read_csv(STRAVA_FOLDER + \"activities.csv\")\n",
    "df = df.rename(columns={df.columns[i] : column_headers[i] for i in range(len(column_headers))})\n",
    "\n",
    "metadata = df[[\"Date\", \"Name\", \"Activitytype\", \"Filename\"]]\n",
    "metadata.to_csv(STRAVA_FOLDER + \"activities/metadata.csv\")\n",
    "\n",
    "# print out all activity types\n",
    "print(\"Activity types in archive:\")\n",
    "print(np.unique(metadata[\"Activitytype\"].values))\n",
    "\n",
    "# cleanup\n",
    "del column_headers\n",
    "del df\n",
    "del metadata"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting non-gpx files, moving gpx files from strava archive\n",
    "In this step non-gpx files in the strava archive (.tcx and .fit) are converted to gpx.\n",
    "\n",
    "All files are then copied into `../gpx/source`\n",
    "\n",
    "If you want to use the strava metadata, make sure that `CONVERT_METADATA`is set to `True`\n",
    "\n",
    "**NOTE**: This part uses system commands to move files and utilizes the CLI of GPS-babel. This probably only works on linux with GPS-babel installed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REMOVE_ORIGINALS = False\n",
    "# If you extracted the metadata from the strava archive,\n",
    "# set to true to update the filenames and copy to gpx folder\n",
    "CONVERT_METADATA = True\n",
    "\n",
    "SOURCE_FOLDER = STRAVA_FOLDER + \"activities/\"\n",
    "DEST_FOLDER = \"../gpx/source/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpxtools import convert_to_gpx\n",
    "convert_to_gpx(SOURCE_FOLDER, DEST_FOLDER, CONVERT_METADATA)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge gpx files\n",
    "This step merges gpx-files into one big gpx file that will be used to generate the heatmaps.\n",
    "\n",
    "You can either merge everything in one folder (the `GPX_FOLDER`, by default the output folder of the prvious step.) or you can use the strava metadata to select by activitytype.\n",
    "See the comment in the code for how to define the dictionary to do this\n",
    "\n",
    "**Note**: depending on how much data you have, this can take a while. Definitely setting `SIMPLIFY=True` causes it to take a while. It is however NOT recommended to turn this of, this option produces significantly smaller output files resulting in faster processing in later steps with better results!\n",
    "\n",
    "Processing 470 cycling trips for a total of 22 000 km took about 5 minutes\n",
    "\n",
    "### Customization\n",
    "The default config removes points that are close together. Additionally all time and elevation data will be removed.\n",
    "This behaviour can be changed by setting the appropriate variables in the next codeblock\n",
    "\n",
    "To toggle removing points: `SIMPLIFY=True/False`\n",
    "\n",
    "To toggle removing time data: `REMOVE_TIME=True/False`\n",
    "\n",
    "To toggle removing elevation data: `REMOVE_ELEVATION=True/False`\n",
    "\n",
    "To toggle removing gpx extensions (such as heartrate): `REMOVE_EXTENSIONS = True`\n",
    "\n",
    "To toggle removing waypoints: `REMOVE_WAYPOINTS = True`\n",
    "\n",
    "### Select by activity type\n",
    "To select by activity type set `SELECT_BY_TYPE` to `True`.\n",
    "Additionally you need to define a dictionary that determines which types end up in which merged gpx file.\n",
    "To do this the dictionary `MERGED_FILES` needs to be defined with the following structure\n",
    "\n",
    "`{\"merged_file_name\" : [\"activitytype1\", \"activitytype2\", ...]}`\n",
    "\n",
    "All activities of a type in the array will be merged together into the gpxfile `merged_file_name`.\n",
    "\n",
    "A list of all activity types in the archive was printed in the step *Extracting Strava metadata*.\n",
    "**Note**: Some names of an activity type have a trailing space in their name for some unknown reason. Don't forget to include this!\n",
    "\n",
    "for an example dictionary: see the block with parameter definitions below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name of output file, irrelevant when selecting by activitytype\n",
    "MERGE_NAME = \"-\"\n",
    "\n",
    "# Directory containing the input gpxfiles (don't forget trailing \"/\")\n",
    "# default: output folder from previous step\n",
    "GPX_FOLDER = \"../gpx/source/\"\n",
    "# Directory where the output will be saved\n",
    "OUT_FOLDER = \"../gpx/output/\"\n",
    "\n",
    "\n",
    "# Parameters that determine what gets removed from the gpx\n",
    "# \"SIMPLIFY\" romoves points that are close togther in the gpx if\n",
    "# removing them does not significantly alter the track\n",
    "SIMPLIFY = True\n",
    "REMOVE_TIME = True\n",
    "REMOVE_ELEVATION = True\n",
    "REMOVE_EXTENSIONS = True\n",
    "REMOVE_WAYPOINTS = True\n",
    "# not implemented yet!\n",
    "REMOVE_SPEED = False\n",
    "\n",
    "\n",
    "# If the gpxfiles are extracted from a strava archive, there is a csv with metadata\n",
    "# present in the archive. If this metadata was prepared and converted along with the gpx files,\n",
    "# this data can be used to select files based on activitytype\n",
    "SELECT_BY_TYPE = True\n",
    "# MERGED_FILES is a dictionary with the following structure:\n",
    "# {merged_file_name : [activitytype1, activitytype2, ...]}\n",
    "# the key should be a string, and will be the name of the output gpx file\n",
    "# the value is an array of activitytypes that will be merged into the corresponding gpx file\n",
    "MERGED_FILES = {\n",
    "        \"merged_ski.gpx\" : [\"AlpineskiÃ«n \"], \n",
    "        \"merged_fiets.gpx\" : [\"Fietsrit\"], \n",
    "        \"merged_stap.gpx\" : [\"Hiken\", \"Wandeling\"], \n",
    "        \"merged_loop.gpx\" : [\"Hardloopsessie\", \"Skeeleren\"]\n",
    "        }\n",
    "#MERGED_FILES = {\"merged_voet.gpx\" : [\"Hardloopsessie\", \"Hiken\", \"Wandeling\", \"Skeeleren\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpxtools import clean_and_merge\n",
    "\n",
    "if not SELECT_BY_TYPE:\n",
    "    # get the names of all the gpxfiles in the GPX_FOLDER\n",
    "    filenames = []\n",
    "    for name in os.listdir(GPX_FOLDER):\n",
    "        # test if extension is .gpx or .GPX\n",
    "        if name[-4:] == \".gpx\" or name[-4:] == \".GPX\":\n",
    "            filenames.append(name)\n",
    "    \n",
    "    # generate merged file\n",
    "    clean_and_merge(filenames, GPX_FOLDER, OUT_FOLDER, SIMPLIFY, REMOVE_TIME, REMOVE_ELEVATION, REMOVE_EXTENSIONS,\n",
    "        REMOVE_WAYPOINTS, REMOVE_SPEED, MERGE_NAME, 20)\n",
    "\n",
    "else:\n",
    "    # iterate over the different output files\n",
    "    df = pd.read_csv(GPX_FOLDER + \"metadata.csv\", index_col=\"Unnamed: 0\")\n",
    "    for merge_name, activity_types in MERGED_FILES.items():\n",
    "        print(\"preparing %s\" %merge_name)\n",
    "        \n",
    "        # iterate over the activities for this file and collect filenames\n",
    "        filenames = []\n",
    "        for activity_type in activity_types:\n",
    "            filenames += list(df.loc[df[\"Activitytype\"] == activity_type][\"Filename\"].values)\n",
    "        # check if there are files found, if so, generate the merged gpx\n",
    "        \n",
    "        if len(filenames) > 0:\n",
    "            clean_and_merge(filenames, GPX_FOLDER, OUT_FOLDER, SIMPLIFY, REMOVE_TIME, REMOVE_ELEVATION, REMOVE_EXTENSIONS,\n",
    "                REMOVE_WAYPOINTS, REMOVE_SPEED, merge_name, 10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate background map\n",
    "This step contains tools to fetch tiles from mapbox, in a user-defined style, and stitch them together into 1 big map image\n",
    "\n",
    "### Usage\n",
    "1) change the variables in the next codeblock to the values you need. i.e., select the right map from the regions.csv file\n",
    "\n",
    "2) run the next two codeblocks and check the info that is printed out.\n",
    "\n",
    "3) If the info is as expected, run the next  three codeblocks. For large maps this can take a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acces token for mapbox and user\n",
    "TOKEN = \"\"\n",
    "USER = \"\"\n",
    "\n",
    "MAP_FOLDER = \"../maps/\"\n",
    "# csv containing information of regions\n",
    "REGION_FILE = MAP_FOLDER + \"regions.csv\"\n",
    "# descriptive name for region of interest, used to fetch map info from regions.csv\n",
    "REGION_NAME = \"Waasmunster-darkheat-14\"\n",
    "\n",
    "# if you intend to print the map, set the DPI value to get the physical size of the image\n",
    "DPI = 200\n",
    "# size in pixels of 1 tile. Default is 256 unless you did \"louche aanpassing\" in the sourcecode of cartopy\n",
    "TILESIZE = 256\n",
    "\n",
    "\n",
    "from maptools import gen_map_metadata, images_for_domain, merge_tiles, write_map_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_tiles, area, image_pixel_size, area_tile_coords, map_coords, data, description = gen_map_metadata(\n",
    "    REGION_FILE, REGION_NAME, TOKEN, USER, DPI=DPI, TILESIZE=TILESIZE)\n",
    "\n",
    "write_map_csv(MAP_FOLDER, data)\n",
    "\n",
    "print(description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the tiles\n",
    "tiles = images_for_domain(map_tiles, area, data[\"Zoom\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = merge_tiles(tiles, image_pixel_size, area_tile_coords, data[\"TileSize\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write image to disk\n",
    "PIL_image = Image.fromarray(img)\n",
    "PIL_image.save(\"%s%s.png\"%(MAP_FOLDER, data[\"MapName\"]), \"png\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# descriptive name for region of interest, used in filename for outputfiles\n",
    "MAP_NAME = \"Leuven-darkheat-14_14\"\n",
    "# INFO: these variables are required to fetch the metadata of the right map\n",
    "\n",
    "\n",
    "# gpx data to use\n",
    "ACTIVITY_TYPES = [\"voet\", \"fiets\"]\n",
    "GPX_SOURCES = [\n",
    "    [\"../gpx/output/merged_stap.gpx\", \"../gpx/output/merged_loop.gpx\"],\n",
    "    [\"../gpx/output/merged_fiets.gpx\"]\n",
    "]\n",
    "# construct dictionary\n",
    "SOURCES = {ACTIVITY_TYPES[i] : GPX_SOURCES[i] for i in range(len(ACTIVITY_TYPES))}\n",
    "\n",
    "#GPX_SOURCE = \"../gpx/output/merged_voet.gpx\"\n",
    "\n",
    "# folder to save the heatlayer to\n",
    "HEAT_FOLDER = \"../heatlayers/\"\n",
    "HEATMAP_FOLDER = \"../heatmaps/\"\n",
    "\n",
    "# wether to create the heatmap or not, and where to look for the map\n",
    "CREATE_HEATMAP = True\n",
    "MAP_FOLDER = \"../maps/\"\n",
    "\n",
    "\n",
    "\n",
    "# heatmapshit\n",
    "\n",
    "# apply a (naive) denoising. sometimes two tracks on the same road go through adjacent pixels due to small errors in the data,\n",
    "# leading to half the number of tracks going through both pixels. If they do overlap a bit further, this leads to noisy lines\n",
    "# this is fixed by setting the value of each pixel, THAT IS CONTAINED IN A TRACK, to the max value of all pixels in a small region.\n",
    "DENOISE = True\n",
    "DENOISE_RADIUS = 2  # how much pixels around every pixel to use for denoising. Radius=1 uses a 3x3 square as mask, Radius=2 a 5x5 square etc\n",
    "\n",
    "# when using high resolution maps, the single pixel wide track can be hard to spot\n",
    "# this option widens the track by doing a denoising, but now also setting the pixels\n",
    "# OUTSIDE the track to the max of the mask, leading to a wider track.\n",
    "# is only carried out together with denoising\n",
    "WIDEN = False\n",
    "WIDEN_RADIUS = 1\n",
    "\n",
    "# inverse cdf transform\n",
    "LINEAR_MAX = 3\n",
    "LINEAR_WEIGHT = 1/3\n",
    "\n",
    "# make sure this is at least as long as the dictionary with GPX_SOURCES\n",
    "COLOR_MAPS = [\"BuPu_r\", \"YlOrRd_r\"]\n",
    "CMAPS = {ACTIVITY_TYPES[i] : COLOR_MAPS[i] for i in range(len(ACTIVITY_TYPES))}\n",
    "# alpha of the generated heatlayers\n",
    "ALPHA = 1.0\n",
    "\n",
    "del ACTIVITY_TYPES, GPX_SOURCES, COLOR_MAPS\n",
    "\n",
    "from heatmaptools import LatLonToMapPixel, generate_pixel_counts, generate_point_density, generate_heat_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the map metadata\n",
    "df = pd.read_csv(\"%smaps_metadata.csv\" %MAP_FOLDER, sep=\",\")\n",
    "df = df.set_index(\"MapName\")\n",
    "MAP_DATA = df.loc[MAP_NAME]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each pixel, count how many tracks pass through it of each type\n",
    "pixel_sets = { activity_type : [] for activity_type in SOURCES.keys() }\n",
    "\n",
    "# iterate over all sources\n",
    "for source in SOURCES.keys():\n",
    "    for gpx_file in SOURCES[source]:\n",
    "        print(\"Processing %s\" %gpx_file)\n",
    "        pixel_sets[source] += generate_pixel_counts(gpx_file, MAP_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the heatmaps\n",
    "for activity_type in SOURCES.keys():\n",
    "    print(\"producing layer %s\" %activity_type)\n",
    "    point_dense = generate_point_density(pixel_sets[activity_type], MAP_DATA, DENOISE, DENOISE_RADIUS, WIDEN, WIDEN_RADIUS)\n",
    "    heat_layer = generate_heat_layer(point_dense, LINEAR_MAX, LINEAR_WEIGHT, plt.get_cmap(CMAPS[activity_type]), ALPHA)\n",
    "    heat_layer = np.flip(heat_layer,0)\n",
    "    heat_layer = (255*heat_layer).astype(np.uint8)\n",
    "    big_img = Image.fromarray(heat_layer)\n",
    "    big_img.save(\"%s%s-%s.png\" %(HEAT_FOLDER,MAP_NAME,activity_type), \"png\")\n",
    "\n",
    "    del point_dense, heat_layer, big_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if CREATE_HEATMAP:\n",
    "    background = Image.open(\"%s%s.png\" %(MAP_FOLDER, MAP_NAME))\n",
    "    for activity_type in SOURCES.keys():\n",
    "        print(\"pasting layer %s\" %activity_type)\n",
    "        heat_layer = Image.open(\"%s%s-%s.png\" %(HEAT_FOLDER,MAP_NAME,activity_type))\n",
    "        background.paste(heat_layer, (0,0), heat_layer)\n",
    "    background.save(\"%s%s.png\" %(HEATMAP_FOLDER, MAP_NAME), \"png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
